Your Instagram posts help Facebook crack down on terrorists
Artificial intelligence that detects posts from terrorists. A virtual reality version of yourself that looks and moves like a real human. Instant translations of thousands of languages. For the second day of F8 developer's conference in San Jose, Facebook switched from data scandal apologies and new features, such as its dating service, to cool experimental projects and ... ethics.   Facebook executives on Wednesday outlined the company's latest advances in artificial intelligence, connectivity and virtual reality. The research is shaping the next generation of Facebook. For example, it believes people will one day be hanging out together in virtual reality versions of their kitchens.   Amid Facebook's tumultuous past year of scandals -- including election interference, fake news and Cambridge Analytica's use of personal data -- the company is focusing on the positive side of innovation across its products.   Another example is how Facebook is using AI to screen and remove content -- often before it is ever seen by regular users, according to CTO Mike Schroepfer.   In the first quarter of this year, Facebook's automated systems flagged 2 million pieces of "terrorist propaganda" on the site -- 99% of which were detected before it was seen by humans. Using technology such as natural language processing, the tools can flag bullying, hate speech and threats of self-harm, according to Schroepfer.   Content moderation is a pressing concern for technology companies. YouTube has struggled with offensive content, including conspiracy theories and disturbing children's videos. Facebook has alternately been accused of not doing enough to take down posts that include hate speech or removing too much content, such as women publicly naming their harassers.   While both companies have said they're adding more human screeners, the massive volume of posts is nearly impossible handle manually.   About halfway through the presentation, the company took a detour to talk in-depth about the ethics issues with AI.   "Process checks alone are not enough. We need to ensure that our actions and consequences are aligned with an ethical framework," said Facebook data scientist Isabel Kloumann.   Kloumann said Facebook has guidelines to detect and correct any biases that show up in its algorithms. The company continues to grow its bias-checking systems to "evaluate the personal and societal implications of every product we build."   Users of Facebook-owned Instagram might be surprised to learn their pictures of birthday parties and dogs are being used to train these artificial intelligence tools. Facebook has scanned 3.5 billion publicly tagged photos to teach its systems nuances like a cupcake verses a muffin.   Facebook also showed off work it's doing on incredibly realistic avatars for virtual reality that move their lips along with the words you're saying in real time.   The second day of F8 is typically reserved for this kind of futuristic technologies. Last year, Regina Dugan, the former head of Facebook's Building 8, teased research about typing with your brain and hearing with your skin. Updates on those projects were not mentioned at this year's conference.  